{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "#tf.set_random_seed(42)\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM, Dropout\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.core import Dense, Activation, Dropout, RepeatVector\n",
    "from keras.optimizers import RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import sys\n",
    "import heapq\n",
    "import seaborn as sns\n",
    "from pylab import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 12, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 581886\n"
     ]
    }
   ],
   "source": [
    "path = '1661-0.txt'\n",
    "text = open(path,encoding=\"utf8\").read().lower()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193949\n"
     ]
    }
   ],
   "source": [
    "SEQUENCE_LENGTH = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - SEQUENCE_LENGTH, step):\n",
    "    sentences.append(text[i: i + SEQUENCE_LENGTH])\n",
    "    next_chars.append(text[i + SEQUENCE_LENGTH])\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(sentences), SEQUENCE_LENGTH, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(SEQUENCE_LENGTH, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gere\n"
     ]
    }
   ],
   "source": [
    "print(\"gere\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1440/1440 [==============================] - 87s 59ms/step - loss: 2.2555 - accuracy: 0.3516 - val_loss: 2.1174 - val_accuracy: 0.4314\n",
      "Epoch 2/20\n",
      "1440/1440 [==============================] - 88s 61ms/step - loss: 1.6361 - accuracy: 0.5107 - val_loss: 2.0576 - val_accuracy: 0.4342\n",
      "Epoch 3/20\n",
      "1440/1440 [==============================] - 88s 61ms/step - loss: 1.5116 - accuracy: 0.5442 - val_loss: 2.0449 - val_accuracy: 0.4470\n",
      "Epoch 4/20\n",
      "1440/1440 [==============================] - 89s 62ms/step - loss: 1.4461 - accuracy: 0.5612 - val_loss: 2.0330 - val_accuracy: 0.4542\n",
      "Epoch 5/20\n",
      "1440/1440 [==============================] - 88s 61ms/step - loss: 1.4146 - accuracy: 0.5711 - val_loss: 2.0413 - val_accuracy: 0.4535\n",
      "Epoch 6/20\n",
      "1440/1440 [==============================] - 86s 60ms/step - loss: 1.3950 - accuracy: 0.5755 - val_loss: 2.0457 - val_accuracy: 0.4595\n",
      "Epoch 7/20\n",
      "1440/1440 [==============================] - 87s 61ms/step - loss: 1.3629 - accuracy: 0.5848 - val_loss: 2.0607 - val_accuracy: 0.4585\n",
      "Epoch 8/20\n",
      "1440/1440 [==============================] - 85s 59ms/step - loss: 1.3487 - accuracy: 0.5892 - val_loss: 2.0483 - val_accuracy: 0.4583\n",
      "Epoch 9/20\n",
      "1440/1440 [==============================] - 87s 60ms/step - loss: 1.3311 - accuracy: 0.5921 - val_loss: 2.0539 - val_accuracy: 0.4542\n",
      "Epoch 10/20\n",
      "1440/1440 [==============================] - 86s 60ms/step - loss: 1.3219 - accuracy: 0.5952 - val_loss: 2.0589 - val_accuracy: 0.4528\n",
      "Epoch 11/20\n",
      "1440/1440 [==============================] - 86s 60ms/step - loss: 1.3120 - accuracy: 0.5972 - val_loss: 2.0591 - val_accuracy: 0.4570\n",
      "Epoch 12/20\n",
      "1440/1440 [==============================] - 87s 60ms/step - loss: 1.3009 - accuracy: 0.6027 - val_loss: 2.0609 - val_accuracy: 0.4621\n",
      "Epoch 13/20\n",
      "1440/1440 [==============================] - 88s 61ms/step - loss: 1.2973 - accuracy: 0.6029 - val_loss: 2.0835 - val_accuracy: 0.4640\n",
      "Epoch 14/20\n",
      "1440/1440 [==============================] - 87s 61ms/step - loss: 1.2850 - accuracy: 0.6040 - val_loss: 2.0988 - val_accuracy: 0.4583\n",
      "Epoch 15/20\n",
      "1440/1440 [==============================] - 87s 61ms/step - loss: 1.2786 - accuracy: 0.6057 - val_loss: 2.0851 - val_accuracy: 0.4595\n",
      "Epoch 16/20\n",
      "1440/1440 [==============================] - 89s 62ms/step - loss: 1.2737 - accuracy: 0.6079 - val_loss: 2.0865 - val_accuracy: 0.4629\n",
      "Epoch 17/20\n",
      "1440/1440 [==============================] - 88s 61ms/step - loss: 1.2700 - accuracy: 0.6070 - val_loss: 2.1361 - val_accuracy: 0.4620\n",
      "Epoch 18/20\n",
      "1440/1440 [==============================] - 90s 62ms/step - loss: 1.2682 - accuracy: 0.6088 - val_loss: 2.1097 - val_accuracy: 0.4679\n",
      "Epoch 19/20\n",
      "1440/1440 [==============================] - 89s 62ms/step - loss: 1.2597 - accuracy: 0.6108 - val_loss: 2.0715 - val_accuracy: 0.4687\n",
      "Epoch 20/20\n",
      "1440/1440 [==============================] - 88s 61ms/step - loss: 1.2589 - accuracy: 0.6127 - val_loss: 2.1045 - val_accuracy: 0.4663\n"
     ]
    }
   ],
   "source": [
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "history = model.fit(X, y, validation_split=0.05, batch_size=128, epochs=20, shuffle=True).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('keras_model.h5')\n",
    "pickle.dump(history, open(\"history.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('keras_model.h5')\n",
    "history = pickle.load(open(\"history.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(text):\n",
    "    x = np.zeros((1, SEQUENCE_LENGTH, len(chars)))\n",
    "    for t, char in enumerate(text):\n",
    "        x[0, t, char_indices[char]] = 1.\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, top_n=3):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds)\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    \n",
    "    return heapq.nlargest(top_n, range(len(preds)), preds.take)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_completion(text):\n",
    "    original_text = text\n",
    "    generated = text\n",
    "    completion = ''\n",
    "    while True:\n",
    "        x = prepare_input(text)\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, top_n=1)[0]\n",
    "        next_char = indices_char[next_index]\n",
    "        text = text[1:] + next_char\n",
    "        completion += next_char\n",
    "        \n",
    "        if len(original_text + completion) + 2 > len(original_text) and next_char == ' ':\n",
    "            return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_completions(text, n=3):\n",
    "    x = prepare_input(text)\n",
    "    print(\"gf\")\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    print(\"fg\")\n",
    "    next_indices = sample(preds, n)\n",
    "    print(text)\n",
    "    print(predict_completion(text[1:]))\n",
    "#     print(indices_char[16]+predict_completion(text[1:]+indices_char[16]))\n",
    "    return [indices_char[idx] + predict_completion(text[1:] + indices_char[idx]) for idx in next_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = [\n",
    "    \"It is not a lack of love, but a lack of friendship that makes unhappy marriages.\",\n",
    "    \"That which does not kill us makes us stronger.\",\n",
    "    \"I'm not upset that you lied to me, I'm upset that from now on I can't believe you.\",\n",
    "    \"And those who were seen dancing were thought to be insane by those who could not hear the music.\",\n",
    "    \"It is hard enough to remember my opinions, without also remembering my reasons for them!\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is not a lack of love, but a lack of \n",
      "gf\n",
      "fg\n",
      "it is not a lack of love, but a lack of \n",
      "bsommsfom \n",
      "['the ', 'a ', 'some ', 'his ', 'conserks ']\n",
      "\n",
      "that which does not kill us makes us str\n",
      "gf\n",
      "fg\n",
      "that which does not kill us makes us str\n",
      "ag \n",
      "['ong ', 'ike ', 'eet, ', 'uck ', 'ange ']\n",
      "\n",
      "i'm not upset that you lied to me, i'm u\n",
      "gf\n",
      "fg\n",
      "i'm not upset that you lied to me, i'm u\n",
      "bmlso \n",
      "['nder ', 'pon ', 'sed ', 'lle ', 'ttical ']\n",
      "\n",
      "and those who were seen dancing were tho\n",
      "gf\n",
      "fg\n",
      "and those who were seen dancing were tho\n",
      "emsab-ifbdaui \n",
      "['ught ', 'ment ', 'se ', 'ok ', 'ing ']\n",
      "\n",
      "it is hard enough to remember my opinion\n",
      "gf\n",
      "fg\n",
      "it is hard enough to remember my opinion\n",
      "ussl \n",
      "['. ', ', ', ' of ', '\\nwhich ', '?’\\n\\n“‘i ']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for q in quotes:\n",
    "    seq = q[:40].lower()\n",
    "    print(seq)\n",
    "    print(predict_completions(seq, 5))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
